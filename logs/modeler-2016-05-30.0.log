20160530-19:32:48.573 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 2606 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160530-19:32:50.723 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160530-19:32:51.647 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160530-19:32:53.513 [MODELER] [main] [31mWARN [0;39m [36mo.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext[0;39m - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'corpusBuilder': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.librairy.modeler.lda.online.builder.SparkBuilder org.librairy.modeler.lda.online.builder.CorpusBuilder.sparkBuilder; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkBuilder': Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp 
20160530-19:32:53.531 [MODELER] [main] [1;31mERROR[0;39m [36mo.s.b.SpringApplication[0;39m - Application startup failed 
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'corpusBuilder': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.librairy.modeler.lda.online.builder.SparkBuilder org.librairy.modeler.lda.online.builder.CorpusBuilder.sparkBuilder; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkBuilder': Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:334) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1208) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:755) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:762) ~[spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480) ~[spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:322) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:970) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:959) [spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.librairy.Application.main(Application.java:79) [classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
Caused by: org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.librairy.modeler.lda.online.builder.SparkBuilder org.librairy.modeler.lda.online.builder.CorpusBuilder.sparkBuilder; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkBuilder': Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:561) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:331) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	... 44 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkBuilder': Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:136) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:408) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1564) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1120) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1044) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:942) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:533) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	... 46 common frames omitted
Caused by: java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:665) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:601) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2596) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.spark.SparkContext$$anonfun$setCheckpointDir$2.apply(SparkContext.scala:2076) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext$$anonfun$setCheckpointDir$2.apply(SparkContext.scala:2074) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.Option.map(Option.scala:145) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.SparkContext.setCheckpointDir(SparkContext.scala:2074) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.api.java.JavaSparkContext.setCheckpointDir(JavaSparkContext.scala:707) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.SparkBuilder.setup(SparkBuilder.java:67) ~[classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:349) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:300) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:133) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	... 58 common frames omitted
Caused by: java.net.UnknownHostException: tmp
	... 83 common frames omitted
20160530-19:32:53.532 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'corpusBuilder': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.librairy.modeler.lda.online.builder.SparkBuilder org.librairy.modeler.lda.online.builder.CorpusBuilder.sparkBuilder; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkBuilder': Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:334) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1208) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:755) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:762) ~[spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480) ~[spring-context-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:690) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:322) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:970) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:959) ~[spring-boot-1.2.8.RELEASE.jar:1.2.8.RELEASE]
	at org.librairy.Application.main(Application.java:79) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
Caused by: org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.librairy.modeler.lda.online.builder.SparkBuilder org.librairy.modeler.lda.online.builder.CorpusBuilder.sparkBuilder; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkBuilder': Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:561) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:331) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	... 44 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sparkBuilder': Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:136) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:408) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1564) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1120) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1044) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:942) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:533) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	... 46 common frames omitted
Caused by: java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:665) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:601) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2596) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.spark.SparkContext$$anonfun$setCheckpointDir$2.apply(SparkContext.scala:2076) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext$$anonfun$setCheckpointDir$2.apply(SparkContext.scala:2074) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.Option.map(Option.scala:145) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.SparkContext.setCheckpointDir(SparkContext.scala:2074) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.api.java.JavaSparkContext.setCheckpointDir(JavaSparkContext.scala:707) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.SparkBuilder.setup(SparkBuilder.java:67) ~[classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:349) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:300) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:133) ~[spring-beans-4.1.9.RELEASE.jar:4.1.9.RELEASE]
	... 58 common frames omitted
Caused by: java.net.UnknownHostException: tmp
	... 83 common frames omitted
20160530-19:33:42.544 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 2613 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160530-19:33:44.532 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160530-19:33:45.234 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160530-19:33:46.909 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.595 seconds (JVM running for 5.258) 
20160530-19:33:46.910 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160530-19:33:46.910 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160530-19:33:46.910 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=100, numIterations=100, corpusSize=10, vocabulary=100words 
20160530-19:33:46.910 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160530-19:33:47.146 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160530-19:33:48.465 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160530-19:33:48.944 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - DataFrame loaded 
20160530-19:33:48.944 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160530-19:33:48.973 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
java.lang.IllegalArgumentException: requirement failed: Column tokens must be of type equal to one of the following types: [ArrayType(StringType,true), ArrayType(StringType,false)] but was actually of type StringType.
	at scala.Predef$.require(Predef.scala:233) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.ml.util.SchemaUtils$.checkColumnTypes(SchemaUtils.scala:58) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.feature.CountVectorizerParams$class.validateAndTransformSchema(CountVectorizer.scala:74) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.feature.CountVectorizer.validateAndTransformSchema(CountVectorizer.scala:110) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.feature.CountVectorizer.transformSchema(CountVectorizer.scala:171) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:173) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:173) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:51) ~[scala-library-2.10.6.jar:na]
	at scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:60) ~[scala-library-2.10.6.jar:na]
	at scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:108) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.ml.Pipeline.transformSchema(Pipeline.scala:173) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:68) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:127) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.train(ModelBuilder.java:176) ~[classes/:na]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:90) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
20160530-19:40:09.442 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 2636 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160530-19:40:11.440 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160530-19:40:12.122 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160530-19:40:13.769 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.563 seconds (JVM running for 5.233) 
20160530-19:40:13.770 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160530-19:40:13.771 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160530-19:40:13.771 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=100, numIterations=100, corpusSize=10, vocabulary=100words 
20160530-19:40:13.771 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160530-19:40:13.930 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160530-19:40:14.955 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160530-19:40:15.352 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - DataFrame loaded 
20160530-19:40:15.376 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160530-19:40:15.386 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160530-19:43:39.098 [MODELER] [hread-3] [1;31mERROR[0;39m [36mo.a.s.s.LiveListenerBus[0;39m - SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@a5ad32b) 
20160530-19:43:39.098 [MODELER] [hread-3] [1;31mERROR[0;39m [36mo.a.s.s.LiveListenerBus[0;39m - SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1464630219098,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down)) 
20160530-19:43:39.102 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:806) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:804) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:804) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1658) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1581) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext$$anonfun$stop$9.apply$mcV$sp(SparkContext.scala:1740) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1229) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1739) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext$$anonfun$3.apply$mcV$sp(SparkContext.scala:596) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:267) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1765) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.util.Try$.apply(Try.scala:161) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:218) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1858) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.feature.CountVectorizer.fit(CountVectorizer.scala:154) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.feature.CountVectorizer.fit(CountVectorizer.scala:110) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:144) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:140) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at scala.collection.Iterator$class.foreach(Iterator.scala:727) ~[scala-library-2.10.6.jar:na]
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157) ~[scala-library-2.10.6.jar:na]
	at scala.collection.IterableViewLike$Transformed$class.foreach(IterableViewLike.scala:42) ~[scala-library-2.10.6.jar:na]
	at scala.collection.SeqViewLike$AbstractTransformed.foreach(SeqViewLike.scala:43) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:140) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.train(ModelBuilder.java:187) ~[classes/:na]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:90) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
20160530-19:43:46.984 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 2658 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160530-19:43:48.923 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160530-19:43:49.609 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160530-19:43:51.255 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.514 seconds (JVM running for 5.168) 
20160530-19:43:51.256 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160530-19:43:51.256 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160530-19:43:51.256 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100words 
20160530-19:43:51.256 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160530-19:43:51.410 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160530-19:43:52.440 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160530-19:43:52.821 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Global DataFrame loaded 
20160530-19:43:52.834 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160530-19:43:52.844 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160530-19:47:48.366 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
org.apache.spark.SparkException: Task not serializable
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:304) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:294) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:122) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.clean(SparkContext.scala:2055) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$map$1.apply(RDD.scala:324) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$map$1.apply(RDD.scala:323) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.map(RDD.scala:323) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.api.java.JavaRDDLike$class.mapToPair(JavaRDDLike.scala:120) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.api.java.AbstractJavaRDDLike.mapToPair(JavaRDDLike.scala:46) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.train(ModelBuilder.java:193) ~[classes/:na]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:90) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
Caused by: java.io.NotSerializableException: org.librairy.modeler.lda.online.builder.ModelBuilder
Serialization stack:
	- object not serializable (class: org.librairy.modeler.lda.online.builder.ModelBuilder, value: org.librairy.modeler.lda.online.builder.ModelBuilder@3065efd0)
	- field (class: org.librairy.modeler.lda.online.builder.ModelBuilder$1, name: this$0, type: class org.librairy.modeler.lda.online.builder.ModelBuilder)
	- object (class org.librairy.modeler.lda.online.builder.ModelBuilder$1, org.librairy.modeler.lda.online.builder.ModelBuilder$1@5020b59f)
	- field (class: org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1, name: x$330, type: interface org.apache.spark.api.java.function.PairFunction)
	- object (class org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1, <function1>)
	at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:301) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	... 42 common frames omitted
20160530-19:50:37.455 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 2681 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160530-19:50:39.616 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160530-19:50:40.327 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160530-19:50:41.886 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.673 seconds (JVM running for 5.346) 
20160530-19:50:41.887 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160530-19:50:41.887 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160530-19:50:41.888 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100words 
20160530-19:50:41.888 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160530-19:50:42.041 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160530-19:50:43.142 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160530-19:50:43.523 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Global DataFrame loaded 
20160530-19:50:43.536 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160530-19:50:43.546 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160530-19:54:39.037 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160530-19:54:39.199 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160530-19:58:39.202 [MODELER] [orker-0] [1;31mERROR[0;39m [36mo.a.s.e.Executor[0;39m - Exception in task 0.0 in stage 8.0 (TID 122) 
java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:200) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.sql.Row$class.getAs(Row.scala:325) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:192) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.lambda$train$315428c4$1(ModelBuilder.java:204) ~[classes/:na]
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.Task.run(Task.scala:89) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_73]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_73]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_73]
20160530-19:58:39.212 [MODELER] [etter-2] [31mWARN [0;39m [36mo.a.s.s.TaskSetManager[0;39m - Lost task 0.0 in stage 8.0 (TID 122, localhost): java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:200)
	at org.apache.spark.sql.Row$class.getAs(Row.scala:325)
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:192)
	at org.librairy.modeler.lda.online.builder.ModelBuilder.lambda$train$315428c4$1(ModelBuilder.java:204)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285)
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
 
20160530-19:58:39.213 [MODELER] [etter-2] [1;31mERROR[0;39m [36mo.a.s.s.TaskSetManager[0;39m - Task 0 in stage 8.0 failed 1 times; aborting job 
20160530-19:58:39.219 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 1 times, most recent failure: Lost task 0.0 in stage 8.0 (TID 122, localhost): java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:200)
	at org.apache.spark.sql.Row$class.getAs(Row.scala:325)
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:192)
	at org.librairy.modeler.lda.online.builder.ModelBuilder.lambda$train$315428c4$1(ModelBuilder.java:204)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285)
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) ~[scala-library-2.10.6.jar:na]
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.Option.foreach(Option.scala:236) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1858) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:386) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:231) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LDA.run(LDA.scala:324) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LDA.run(LDA.scala:342) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.train(ModelBuilder.java:218) ~[classes/:na]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:90) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:200) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.sql.Row$class.getAs(Row.scala:325) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:192) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.lambda$train$315428c4$1(ModelBuilder.java:204) ~[classes/:na]
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.Task.run(Task.scala:89) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_73]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_73]
	at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_73]
