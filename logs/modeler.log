20160531-09:34:43.926 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 3017 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-09:34:46.015 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-09:34:46.726 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-09:34:48.379 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.712 seconds (JVM running for 5.436) 
20160531-09:34:48.380 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-09:34:48.380 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:34:48.380 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100words 
20160531-09:34:48.380 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:34:49.609 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-09:34:49.620 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-09:34:49.634 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
java.lang.IllegalArgumentException: Field "tokens" does not exist.
	at org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:212) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:212) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at scala.collection.MapLike$class.getOrElse(MapLike.scala:128) ~[scala-library-2.10.6.jar:na]
	at scala.collection.AbstractMap.getOrElse(Map.scala:58) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.sql.types.StructType.apply(StructType.scala:211) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.UnaryTransformer.transformSchema(Transformer.scala:106) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:173) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:173) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:51) ~[scala-library-2.10.6.jar:na]
	at scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:60) ~[scala-library-2.10.6.jar:na]
	at scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:108) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.ml.Pipeline.transformSchema(Pipeline.scala:173) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:68) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:127) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.train(ModelBuilder.java:213) ~[classes/:na]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:90) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
20160531-09:35:35.743 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 3036 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-09:35:37.749 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-09:35:38.474 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-09:35:40.010 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.507 seconds (JVM running for 5.179) 
20160531-09:35:40.011 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-09:35:40.011 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:35:40.011 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100words 
20160531-09:35:40.011 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:35:41.209 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-09:35:41.220 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-09:35:41.943 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160531-09:35:42.085 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160531-09:35:42.139 [MODELER] [orker-0] [1;31mERROR[0;39m [36mo.a.s.e.Executor[0;39m - Exception in task 0.0 in stage 4.0 (TID 3) 
java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:200) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.sql.Row$class.getAs(Row.scala:325) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:192) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.lambda$train$315428c4$1(ModelBuilder.java:230) ~[classes/:na]
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.Task.run(Task.scala:89) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_73]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_73]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_73]
20160531-09:35:42.147 [MODELER] [etter-3] [31mWARN [0;39m [36mo.a.s.s.TaskSetManager[0;39m - Lost task 0.0 in stage 4.0 (TID 3, localhost): java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:200)
	at org.apache.spark.sql.Row$class.getAs(Row.scala:325)
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:192)
	at org.librairy.modeler.lda.online.builder.ModelBuilder.lambda$train$315428c4$1(ModelBuilder.java:230)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285)
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
 
20160531-09:35:42.148 [MODELER] [etter-3] [1;31mERROR[0;39m [36mo.a.s.s.TaskSetManager[0;39m - Task 0 in stage 4.0 failed 1 times; aborting job 
20160531-09:35:42.153 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 3, localhost): java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:200)
	at org.apache.spark.sql.Row$class.getAs(Row.scala:325)
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:192)
	at org.librairy.modeler.lda.online.builder.ModelBuilder.lambda$train$315428c4$1(ModelBuilder.java:230)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285)
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) ~[scala-library-2.10.6.jar:na]
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.Option.foreach(Option.scala:236) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1858) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:386) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:231) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LDA.run(LDA.scala:324) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LDA.run(LDA.scala:342) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.train(ModelBuilder.java:244) ~[classes/:na]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:90) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:200) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.sql.Row$class.getAs(Row.scala:325) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:192) ~[spark-catalyst_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.lambda$train$315428c4$1(ModelBuilder.java:230) ~[classes/:na]
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1018) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.Task.run(Task.scala:89) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_73]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_73]
	at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_73]
20160531-09:39:13.780 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 3053 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-09:39:15.933 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-09:39:16.680 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-09:39:18.534 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 5.006 seconds (JVM running for 6.142) 
20160531-09:39:18.535 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-09:39:18.535 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:39:18.535 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100words 
20160531-09:39:18.535 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:39:19.809 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-09:39:19.821 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-09:39:20.552 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160531-09:39:20.758 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Rows: [[(12,[0,2,3,4,5],[1.0,1.0,1.0,1.0,1.0])], [(12,[0,6,7,8,9,10,11],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])], [(12,[1],[1.0])]] 
20160531-09:40:54.923 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160531-09:40:54.930 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
java.lang.IllegalStateException: SparkContext has been shutdown
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1858) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:386) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:231) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LDA.run(LDA.scala:324) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LDA.run(LDA.scala:342) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.train(ModelBuilder.java:252) ~[classes/:na]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:90) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
20160531-09:43:12.769 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 3076 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-09:43:14.805 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-09:43:15.608 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-09:43:17.396 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.886 seconds (JVM running for 5.702) 
20160531-09:43:17.397 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-09:43:17.398 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:43:17.398 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100words 
20160531-09:43:17.398 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:43:18.618 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-09:43:18.629 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-09:43:19.386 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160531-09:43:19.603 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Rows: [(0,(12,[0,2,3,4,5],[1.0,1.0,1.0,1.0,1.0])), (1,(12,[0,6,7,8,9,10,11],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])), (2,(12,[1],[1.0]))] 
20160531-09:43:41.988 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160531-09:43:41.993 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
java.lang.IllegalStateException: SparkContext has been shutdown
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1858) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:386) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.OnlineLDAOptimizer.initialize(LDAOptimizer.scala:231) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LDA.run(LDA.scala:324) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LDA.run(LDA.scala:342) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.train(ModelBuilder.java:255) ~[classes/:na]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:90) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
20160531-09:45:06.796 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 3095 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-09:45:08.752 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-09:45:09.462 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-09:45:11.057 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.501 seconds (JVM running for 5.169) 
20160531-09:45:11.058 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-09:45:11.058 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:45:11.058 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100words 
20160531-09:45:11.058 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:45:12.200 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-09:45:12.210 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-09:45:12.900 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160531-09:45:13.049 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160531-09:45:13.538 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ## Created LDA Model successfully!!!! 
20160531-09:45:13.538 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Elapsed Time: 0min 2secs 
20160531-09:45:13.538 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Vocabulary Size: 12 
20160531-09:45:13.538 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.t.TrainModelTask[0;39m - Saving the model: /model-10-1-1 
20160531-09:45:13.681 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:665) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:601) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2596) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.spark.SparkHadoopWriter$.createPathFromString(SparkHadoopWriter.scala:170) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1059) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:951) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1457) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel$SaveLoadV1_0$.save(LDAModel.scala:433) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel.save(LDAModel.scala:221) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:94) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
Caused by: java.net.UnknownHostException: tmp
	... 66 common frames omitted
20160531-09:46:27.522 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 3107 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-09:46:29.515 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-09:46:30.237 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-09:46:31.884 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.606 seconds (JVM running for 5.264) 
20160531-09:46:31.886 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-09:46:31.886 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:46:31.886 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100words 
20160531-09:46:31.887 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-09:46:32.037 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160531-09:46:33.070 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160531-09:46:33.482 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Global DataFrame loaded 
20160531-09:46:33.495 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-09:46:33.505 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-09:50:33.523 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160531-09:50:33.686 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160531-09:54:30.269 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ## Created LDA Model successfully!!!! 
20160531-09:54:30.270 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Elapsed Time: 7min 58secs 
20160531-09:54:30.270 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Vocabulary Size: 100 
20160531-09:54:30.270 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.t.TrainModelTask[0;39m - Saving the model: /model-10-1-1 
20160531-09:54:30.431 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:665) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:601) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2596) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.spark.SparkHadoopWriter$.createPathFromString(SparkHadoopWriter.scala:170) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1059) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:951) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1457) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel$SaveLoadV1_0$.save(LDAModel.scala:433) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel.save(LDAModel.scala:221) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:94) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
Caused by: java.net.UnknownHostException: tmp
	... 66 common frames omitted
20160531-13:10:43.852 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 3488 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-13:10:45.864 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-13:10:46.638 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-13:10:48.714 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 5.089 seconds (JVM running for 5.819) 
20160531-13:10:48.715 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-13:10:48.715 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-13:10:48.715 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100 
20160531-13:10:48.715 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-13:10:48.892 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160531-13:10:50.107 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160531-13:10:50.673 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Global DataFrame loaded 
20160531-13:10:51.104 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-13:10:51.116 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-13:14:48.517 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160531-13:14:48.688 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160531-13:14:49.171 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ## Created LDA Model successfully!!!! 
20160531-13:14:49.172 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Elapsed Time: 4min 0secs 
20160531-13:14:49.172 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Vocabulary Size: 100 
20160531-13:14:49.172 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.t.TrainModelTask[0;39m - Saving the model: /model-10-1-1 
20160531-13:14:49.345 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:665) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:601) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2596) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.spark.SparkHadoopWriter$.createPathFromString(SparkHadoopWriter.scala:170) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1059) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:951) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1457) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel$SaveLoadV1_0$.save(LDAModel.scala:433) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel.save(LDAModel.scala:221) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:94) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
Caused by: java.net.UnknownHostException: tmp
	... 66 common frames omitted
20160531-13:17:05.656 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 3505 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-13:17:07.646 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-13:17:08.357 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-13:17:09.990 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.547 seconds (JVM running for 5.329) 
20160531-13:17:09.991 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-13:17:09.991 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-13:17:09.991 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100 
20160531-13:17:09.991 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-13:17:10.158 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160531-13:17:11.177 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160531-13:17:11.560 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Global DataFrame loaded 
20160531-13:17:11.899 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-13:17:11.909 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-13:21:06.983 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160531-13:21:07.140 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160531-13:21:07.543 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ## Created LDA Model successfully!!!! 
20160531-13:21:07.544 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Elapsed Time: 3min 57secs 
20160531-13:21:07.544 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Vocabulary Size: 100 
20160531-13:21:07.544 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.t.TrainModelTask[0;39m - Saving the model: /model-10-1-1 
20160531-13:21:07.684 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
java.lang.IllegalArgumentException: java.net.UnknownHostException: tmp
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:665) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:601) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2596) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.spark.SparkHadoopWriter$.createPathFromString(SparkHadoopWriter.scala:170) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1059) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:951) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1457) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel$SaveLoadV1_0$.save(LDAModel.scala:433) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel.save(LDAModel.scala:221) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:94) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
Caused by: java.net.UnknownHostException: tmp
	... 66 common frames omitted
20160531-13:23:10.536 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 3520 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-13:23:12.519 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-13:23:13.228 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-13:23:14.869 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.572 seconds (JVM running for 5.249) 
20160531-13:23:14.870 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-13:23:14.870 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-13:23:14.870 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100 
20160531-13:23:14.870 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-13:23:15.025 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items limit 10' 
20160531-13:23:16.098 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160531-13:23:16.484 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Global DataFrame loaded 
20160531-13:23:16.814 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-13:23:16.824 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-13:24:57.957 [MODELER] [hread-3] [1;31mERROR[0;39m [36mo.a.s.s.LiveListenerBus[0;39m - SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@33f10afe) 
20160531-13:24:57.957 [MODELER] [hread-3] [1;31mERROR[0;39m [36mo.a.s.s.LiveListenerBus[0;39m - SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1464693897957,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down)) 
20160531-13:24:57.960 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:806) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:804) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:804) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1658) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1581) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext$$anonfun$stop$9.apply$mcV$sp(SparkContext.scala:1740) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1229) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1739) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext$$anonfun$3.apply$mcV$sp(SparkContext.scala:596) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:267) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1765) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at scala.util.Try$.apply(Try.scala:161) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:239) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:218) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1858) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.feature.CountVectorizer.fit(CountVectorizer.scala:154) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.feature.CountVectorizer.fit(CountVectorizer.scala:110) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:144) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:140) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at scala.collection.Iterator$class.foreach(Iterator.scala:727) ~[scala-library-2.10.6.jar:na]
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157) ~[scala-library-2.10.6.jar:na]
	at scala.collection.IterableViewLike$Transformed$class.foreach(IterableViewLike.scala:42) ~[scala-library-2.10.6.jar:na]
	at scala.collection.SeqViewLike$AbstractTransformed.foreach(SeqViewLike.scala:43) ~[scala-library-2.10.6.jar:na]
	at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:140) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.builder.ModelBuilder.train(ModelBuilder.java:215) ~[classes/:na]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:90) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
20160531-14:46:35.657 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 4111 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-14:46:37.735 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-14:46:38.519 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-14:46:40.204 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.787 seconds (JVM running for 5.487) 
20160531-14:46:40.204 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-14:46:40.204 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-14:46:40.205 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100 
20160531-14:46:40.205 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-14:46:40.365 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160531-14:46:41.414 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160531-14:46:42.045 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Global DataFrame loaded 
20160531-14:46:42.388 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a TokenizerModel from the corpus.. 
20160531-14:46:42.398 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - fit a CountVectorizerModel from the corpus.. 
20160531-14:53:07.810 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160531-14:53:07.962 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160531-14:53:08.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ## Created LDA Model successfully!!!! 
20160531-14:53:08.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ##################################################################################### 
20160531-14:53:08.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Model Elapsed Time: 0min 0secs 
20160531-14:53:08.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Total Elapsed Time: 6min 28secs 
20160531-14:53:08.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Vocabulary Size: 100 
20160531-14:53:08.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Corpus Size: 10 
20160531-14:53:08.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Num Iterations: 1 
20160531-14:53:08.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Num Topics: 1 
20160531-14:53:08.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Alpha: 0.1 
20160531-14:53:08.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Beta: 0.1 
20160531-14:53:08.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ##################################################################################### 
20160531-14:53:08.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.t.TrainModelTask[0;39m - Saving the model: /model-10-1-1 
20160531-14:53:09.029 [MODELER] [main] [1;31mERROR[0;39m [36mo.l.Application[0;39m - Error executing test 
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://zavijava.dia.fi.upm.es/tmp/models/model-10-1-1/metadata already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:132) ~[hadoop-mapreduce-client-core-2.6.0.jar:na]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1179) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1156) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1156) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1156) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1060) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:952) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:951) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1457) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1436) ~[spark-core_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel$SaveLoadV1_0$.save(LDAModel.scala:433) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.apache.spark.mllib.clustering.LocalLDAModel.save(LDAModel.scala:221) ~[spark-mllib_2.10-1.6.1.jar:1.6.1]
	at org.librairy.modeler.lda.online.task.TrainModelTask.run(TrainModelTask.java:94) ~[classes/:na]
	at org.librairy.Application.main(Application.java:87) ~[classes/:na]
	at org.librairy.ApplicationTest.launch(ApplicationTest.java:21) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) [junit-4.12.jar:4.12]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) [junit-rt.jar:na]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) [junit-rt.jar:na]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) [junit-rt.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_73]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_73]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_73]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_73]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) [idea_rt.jar:na]
20160531-16:31:34.536 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 4401 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-16:31:36.662 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-16:31:37.431 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-16:31:39.441 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 5.133 seconds (JVM running for 5.951) 
20160531-16:31:39.442 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-16:31:39.442 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-16:31:39.442 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100 
20160531-16:31:39.442 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-16:31:39.603 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160531-16:31:41.209 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160531-16:31:41.680 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Global DataFrame loaded 
20160531-16:31:41.694 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - split each document into words.. 
20160531-16:31:41.751 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Limit to top `vocabSize` most common words and convert to word count vector features 
20160531-16:35:22.752 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building corpus with bag-of-words.. 
20160531-16:35:22.909 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Configure and run LDA 
20160531-16:35:22.919 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - running LDA model builder.. 
20160531-16:38:54.371 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ## Created LDA Model successfully!!!! 
20160531-16:38:54.371 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ##################################################################################### 
20160531-16:38:54.372 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Model Elapsed Time: 3min 31secs 
20160531-16:38:54.372 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Total Elapsed Time: 7min 14secs 
20160531-16:38:54.372 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Vocabulary Size: 100 
20160531-16:38:54.372 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Corpus Size: 10 
20160531-16:38:54.372 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Num Iterations: 1 
20160531-16:38:54.372 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Num Topics: 1 
20160531-16:38:54.372 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Alpha: 0.1 
20160531-16:38:54.372 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Beta: 0.1 
20160531-16:38:54.372 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ##################################################################################### 
20160531-16:38:54.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Topic-0 
20160531-16:38:54.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	message	:0.04617890107976312 
20160531-16:38:54.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	system	:0.029063266406025398 
20160531-16:38:54.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	business	:0.028955227396542094 
20160531-16:38:54.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	transaction	:0.028370523790001757 
20160531-16:38:54.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	fig.	:0.02803629906584592 
20160531-16:38:54.377 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	invention	:0.027085935935898718 
20160531-16:38:54.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	information	:0.026015108090720346 
20160531-16:38:54.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	datum	:0.025684955872488962 
20160531-16:38:54.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	card	:0.024395470702102618 
20160531-16:38:54.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	partner	:0.02437040106497334 
20160531-16:38:54.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ------------------------------------------ 
20160531-16:38:54.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.t.TrainModelTask[0;39m - Saving the model: /model-10-1-1 
20160531-16:38:54.816 [MODELER] [main] [31mWARN [0;39m [36mo.l.m.l.o.t.TrainModelTask[0;39m - Output directory hdfs://zavijava.dia.fi.upm.es/tmp/models/model-10-1-1/metadata already exists 
20160531-16:38:54.816 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Total elapsed Time: 7min 20secs 
20160531-17:24:46.555 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 4953 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-17:24:48.698 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-17:24:49.466 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-17:24:51.378 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 5.123 seconds (JVM running for 5.89) 
20160531-17:24:51.379 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-17:24:51.379 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-17:24:51.379 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100 
20160531-17:24:51.379 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-17:24:51.539 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160531-17:25:26.843 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 4959 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-17:25:28.758 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-17:25:29.439 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-17:25:31.014 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.404 seconds (JVM running for 5.062) 
20160531-17:25:31.015 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-17:25:31.015 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-17:25:31.015 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100 
20160531-17:25:31.015 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-17:25:31.174 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160531-17:30:54.335 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Starting Application on usuariop33.fi.upm.es with PID 4976 (/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes started by cbadenes in /Users/cbadenes/Projects/librairy/modeler-lda-online) 
20160531-17:30:56.352 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.CitesBuilder[0;39m - Loading reference patents from : file:/Users/cbadenes/Projects/librairy/modeler-lda-online/target/classes/cites_uspto.csv 
20160531-17:30:57.158 [MODELER] [main] [31mWARN [0;39m [36mo.a.h.u.NativeCodeLoader[0;39m - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
20160531-17:30:58.968 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Started Application in 4.905 seconds (JVM running for 5.613) 
20160531-17:30:58.969 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - building a new LDA model .. 
20160531-17:30:58.969 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-17:30:58.970 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m -  TRAINING-STAGE: alpha=0.1, beta=0.1, numTopics=1, numIterations=1, corpusSize=10, vocabulary=100 
20160531-17:30:58.970 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ==================================================================================================== 
20160531-17:30:59.133 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Getting texts from Cassandra by 'select uri,tokens from research.items' 
20160531-17:31:00.280 [MODELER] [main] [31mWARN [0;39m [36mc.d.d.c.NettyUtil[0;39m - Found Netty's native epoll transport, but not running on linux-based operating system. Using NIO instead. 
20160531-17:31:00.730 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Global DataFrame loaded 
20160531-17:31:00.743 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Splitting each document into words .. 
20160531-17:31:00.802 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Limiting to top `vocabSize` most common words and convert to word count vector features .. 
20160531-17:56:41.241 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Building a corpus by using bag-of-words .. 
20160531-17:56:41.387 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Configuring LDA .. 
20160531-17:56:41.399 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Running LDA on corpus .. 
20160531-18:25:44.863 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ## Created LDA Model successfully!!!! 
20160531-18:25:44.866 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ##################################################################################### 
20160531-18:25:44.867 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Model Elapsed Time: 29min 3secs 
20160531-18:25:44.867 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Total Elapsed Time: 54min 45secs 
20160531-18:25:44.867 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Vocabulary Size: 100 
20160531-18:25:44.867 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Corpus Size: 10 
20160531-18:25:44.867 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Num Iterations: 1 
20160531-18:25:44.867 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Num Topics: 1 
20160531-18:25:44.867 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Alpha: 0.1 
20160531-18:25:44.867 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Beta: 0.1 
20160531-18:25:44.867 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ##################################################################################### 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - Topic-0 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	packet	:0.0465513074479927 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	network	:0.04427819732680223 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	device	:0.03205606823014747 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	fig.	:0.03078950184963891 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	host	:0.03034160846051723 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	address	:0.025118596705163334 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	embodiment	:0.022324517771106063 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	field	:0.022007368588978185 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	information	:0.019922858117758024 
20160531-18:25:44.873 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - 	label	:0.01986688867374376 
20160531-18:25:44.874 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.b.ModelBuilder[0;39m - ------------------------------------------ 
20160531-18:25:44.874 [MODELER] [main] [34mINFO [0;39m [36mo.l.m.l.o.t.TrainModelTask[0;39m - Saving the model: /model-10-1-1 
20160531-18:25:45.367 [MODELER] [main] [31mWARN [0;39m [36mo.l.m.l.o.t.TrainModelTask[0;39m - Output directory hdfs://zavijava.dia.fi.upm.es/tmp/models/model-10-1-1/metadata already exists 
20160531-18:25:45.367 [MODELER] [main] [34mINFO [0;39m [36mo.l.Application[0;39m - Total elapsed Time: 54min 51secs 
